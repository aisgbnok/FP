{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bi9g4y3b8Na3"
   },
   "source": [
    "# T4 - Final Project\n",
    "\n",
    "Semester 2221, CSEC 520/620, Team 4\\\n",
    "Final Project - URL Classification\\\n",
    "Due by December 14, 2022 11:59 PM EST.\\\n",
    "Accounts for 18% of total grade."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminary Requirements\n",
    "\n",
    "This section ensures that the `python-whois` package is installed.\n",
    "We also download our raw datasets which are stored in a Git repository hosted on GitHub.\n",
    "\n",
    "**Make sure you are running this notebook in an isolated directory, as it will be turned into a Git working directory.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22739,
     "status": "ok",
     "timestamp": 1671052901291,
     "user": {
      "displayName": "Dominic Adams",
      "userId": "18171972707617789133"
     },
     "user_tz": 300
    },
    "id": "CjXlgYCY-C3X",
    "outputId": "abca34ad-858a-4ad6-f8de-f72379843a8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "## Installing Packages #############\n",
      "####################################\n",
      "Requirement already satisfied: python-whois in c:\\users\\anthony\\documents\\venvs\\t4-project\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: future in c:\\users\\anthony\\documents\\venvs\\t4-project\\lib\\site-packages (from python-whois) (0.18.2)\n",
      "\n",
      "####################################\n",
      "## Updating Repository #############\n",
      "####################################\n",
      "Reinitialized existing Git repository in C:/Users/Anthony/Documents/T4-Project/.git/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: remote origin already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/aisgbnok/T4-Project\n",
      " * branch            main       -> FETCH_HEAD\n"
     ]
    }
   ],
   "source": [
    "# Ensure the WHOIS package is installed\n",
    "print(f'{\"\":#^{36}}\\n{\"## Installing Packages \":#<{36}}\\n{\"\":#^{36}}')\n",
    "!pip install python-whois\n",
    "\n",
    "# Download our repo, which contains the RAW datasets\n",
    "print(f'\\n{\"\":#^{36}}\\n{\"## Updating Repository \":#<{36}}\\n{\"\":#^{36}}')\n",
    "!git init\n",
    "!git remote add origin https://github.com/aisgbnok/T4-Project.git\n",
    "!git pull origin main --allow-unrelated-histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aBTTS1_y8-HY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671052903721,
     "user_tz": 300,
     "elapsed": 1303,
     "user": {
      "displayName": "Dominic Adams",
      "userId": "18171972707617789133"
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import whois\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "seNV-O1UyO9q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671052904708,
     "user_tz": 300,
     "elapsed": 152,
     "user": {
      "displayName": "Dominic Adams",
      "userId": "18171972707617789133"
     }
    }
   },
   "outputs": [],
   "source": [
    "def load_data(seed=75, output=False, save=False):\n",
    "  \"\"\"\n",
    "  Loads our separate dataframes and merges them together.\n",
    "  Ensures the columns are equal, normalizes the labels,\n",
    "  and finally shuffles the columns using the seed.\n",
    "\n",
    "  :param seed: Integer value that ensures reproduction of resulting dataframe.\n",
    "  :param output: Whether to print dataframes or not. True or False.\n",
    "  :param save: Whether to save the pandas dataframe. Can be False (default), 'CSV', or 'PICKLE'.\n",
    "  :return: A pandas dataframe that contains a url and label column.\n",
    "           The label column is 0 for benign and 1 for malicious.\n",
    "  \"\"\"\n",
    "  # Get all of our datasets\n",
    "  df_aj = pd.read_csv(os.path.join('datasets', 'raw', 'urls-antonyj.csv'))\n",
    "  df_ms = pd.read_csv(os.path.join('datasets', 'raw', 'urls-manu-siddhartha.csv'))\n",
    "\n",
    "  if output:\n",
    "    print(f'{\"\":#^{36}}\\n{\"## Original \":#<{36}}\\n{\"\":#^{36}}')\n",
    "    print('## urls-antonyj.csv')\n",
    "    display(df_aj)\n",
    "    print('## urls-manu-siddhartha.csv')\n",
    "    display(df_ms)\n",
    "\n",
    "  # Ensure Columns Match\n",
    "  df_ms.columns = df_aj.columns\n",
    "\n",
    "  # Normalize Data, 1 is malicious, 0 is benign\n",
    "  df_aj['label'] = (df_aj['label'] == 'bad').astype(int)\n",
    "  df_ms['label'] = (df_ms['label'] != 'benign').astype(int)\n",
    "\n",
    "  # Merge dataframes\n",
    "  df = pd.merge(df_aj, df_ms, how='outer')\n",
    "\n",
    "  # Keep first exact matches\n",
    "  df = df.drop_duplicates()\n",
    "\n",
    "  # Drop all duplicate urls with conflicting labels\n",
    "  # Prevents some data poisoning, and promotes data integrity\n",
    "  df = df.drop_duplicates(subset='url', keep=False)\n",
    "\n",
    "  # Shuffle using seed value\n",
    "  df = df.sample(frac=1, random_state=seed)\n",
    "\n",
    "  # Reset Index\n",
    "  df = df.reset_index(drop=True)\n",
    "\n",
    "  if output:\n",
    "    print(f'{\"\":#^{36}}\\n{\"## Resulting \":#<{36}}\\n{\"\":#^{36}}')\n",
    "    print('## urls-antonyj.csv')\n",
    "    display(df_aj)\n",
    "    print('## urls-manu-siddhartha.csv')\n",
    "    display(df_ms)\n",
    "    print('## Final')\n",
    "    display(df)\n",
    "\n",
    "  if save == 'PICKLE':\n",
    "    df.to_pickle('datasets/t4-urls.zip')\n",
    "  elif save == 'CSV':\n",
    "    df.to_csv('datasets/t4-urls.csv')\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fapHNhzsKRIE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671052913956,
     "user_tz": 300,
     "elapsed": 6659,
     "user": {
      "displayName": "Dominic Adams",
      "userId": "18171972707617789133"
     }
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "datasetsize = len(dataset.index)\n",
    "mals = dataset[dataset[\"label\"] == 1]\n",
    "malsize = len(mals.index)\n",
    "bensize = datasetsize - malsize\n",
    "print(datasetsize, malsize, bensize)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnWz2KEmPYC9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671052915533,
     "user_tz": 300,
     "elapsed": 2,
     "user": {
      "displayName": "Dominic Adams",
      "userId": "18171972707617789133"
     }
    },
    "outputId": "348f89d6-d839-44fb-f766-787712e2b7bc"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "707514 66447 641067\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-23UmvftFymN"
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "\n",
    "#multithreading the data set\n",
    "def multithreading():\n",
    "  perc = 0.0\n",
    "  threads = []\n",
    "  max_threads = 10\n",
    "  thread_num = 1\n",
    "  while perc < 1:\n",
    "    if len(threads) >= max_threads:\n",
    "      for thread in threads:\n",
    "        thread.join()\n",
    "        print(\"Thread \"+str(thread_num)+\" done\")\n",
    "        thread_num+=1\n",
    "    print(\"perc \"+str(perc))\n",
    "    thread = threading.Thread(target=checker, args=(perc*100, dataset.iloc[int(perc*len(dataset)):int((perc+0.01)*len(dataset))]))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    perc = perc + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sld7LbyH99_H"
   },
   "outputs": [],
   "source": [
    "#numsection -> the percent into the data that it is\n",
    "#data -> the data of the current section\n",
    "def checker(numsection, data):\n",
    "  rows = []\n",
    "  for index, row in data.iterrows():\n",
    "    w = None\n",
    "    try:\n",
    "      w = whois.whois(data.iloc[index][\"url\"])\n",
    "    except:\n",
    "      continue\n",
    "    if w.domain_name != \"null\" and w.domain_name is not None:\n",
    "      rowdict = {}\n",
    "      rowdict[\"originalurl\"] = data.iloc[index][\"url\"]\n",
    "      rowdict.update(dict(w))\n",
    "      rows.append(rowdict)\n",
    "  whoisframe = pd.DataFrame(rows)\n",
    "  whoisframe.to_csv('csv/whoisdata' + str(numsection) + '.csv')\n",
    "  print(\"csv made\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Import the drive module from the Google Colab library\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount your personal Google Drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "# Immediately change the current directory to the shared drive.\n",
    "# This will reduce the chance that your personal drive will be modified erroneously.\n",
    "os.chdir('/content/drive/Shareddrives/CSEC 620 Group 4/Final Project')"
   ],
   "metadata": {
    "id": "vEiC2csg0Mim",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671052939534,
     "user_tz": 300,
     "elapsed": 17294,
     "user": {
      "displayName": "Dominic Adams",
      "userId": "18171972707617789133"
     }
    },
    "outputId": "7a849995-efe7-4489-e547-6d2efcb03918"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D17LNlWURSxW"
   },
   "outputs": [],
   "source": [
    "#multithreading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QGBK5Xm71NnU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671052945974,
     "user_tz": 300,
     "elapsed": 2559,
     "user": {
      "displayName": "Dominic Adams",
      "userId": "18171972707617789133"
     }
    },
    "outputId": "4ff496c8-dc71-44d2-b465-6d944bac9915"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "whoisdata5.0.csv\n",
      "whoisdata2.0.csv\n",
      "whoisdata3.0.csv\n",
      "whoisdata1.0.csv\n",
      "whoisdata7.000000000000001.csv\n",
      "whoisdata8.0.csv\n",
      "whoisdata4.0.csv\n",
      "whoisdata9.0.csv\n",
      "whoisdata6.000000000000001.csv\n",
      "whoisdata10.0.csv\n",
      "whoisdata10.999999999999998.csv\n",
      "whoisdata11.999999999999998.csv\n",
      "whoisdata12.999999999999998.csv\n",
      "whoisdata13.999999999999998.csv\n",
      "whoisdata15.0.csv\n",
      "whoisdata16.0.csv\n",
      "whoisdata17.0.csv\n",
      "whoisdata18.000000000000004.csv\n",
      "whoisdata19.000000000000004.csv\n",
      "whoisdata20.000000000000004.csv\n",
      "whoisdata21.000000000000004.csv\n",
      "whoisdata22.000000000000007.csv\n",
      "whoisdata23.000000000000007.csv\n",
      "whoisdata24.000000000000007.csv\n",
      "whoisdata25.000000000000007.csv\n",
      "whoisdata26.000000000000007.csv\n",
      "whoisdata27.000000000000007.csv\n",
      "whoisdata28.000000000000007.csv\n",
      "whoisdata29.00000000000001.csv\n",
      "whoisdata30.00000000000001.csv\n",
      "whoisdata31.00000000000001.csv\n",
      "whoisdata32.000000000000014.csv\n",
      "whoisdata33.000000000000014.csv\n",
      "whoisdata34.000000000000014.csv\n",
      "whoisdata35.000000000000014.csv\n",
      "whoisdata36.000000000000014.csv\n",
      "whoisdata37.000000000000014.csv\n",
      "whoisdata38.000000000000014.csv\n",
      "whoisdata39.00000000000002.csv\n",
      "whoisdata40.00000000000002.csv\n",
      "whoisdata41.00000000000002.csv\n",
      "whoisdata42.00000000000002.csv\n",
      "whoisdata43.00000000000002.csv\n",
      "whoisdata44.00000000000002.csv\n",
      "whoisdata45.00000000000002.csv\n",
      "whoisdata46.00000000000002.csv\n",
      "whoisdata47.00000000000003.csv\n",
      "whoisdata48.00000000000003.csv\n",
      "whoisdata49.00000000000003.csv\n",
      "whoisdata50.00000000000002.csv\n",
      "whoisdata51.00000000000002.csv\n",
      "whoisdata52.00000000000002.csv\n",
      "whoisdata53.00000000000003.csv\n",
      "whoisdata54.00000000000003.csv\n",
      "whoisdata55.00000000000003.csv\n",
      "whoisdata56.00000000000003.csv\n",
      "whoisdata57.00000000000003.csv\n",
      "whoisdata58.00000000000003.csv\n",
      "whoisdata59.00000000000003.csv\n",
      "whoisdata60.00000000000003.csv\n",
      "whoisdata61.00000000000003.csv\n",
      "whoisdata62.000000000000036.csv\n",
      "whoisdata63.000000000000036.csv\n",
      "whoisdata64.00000000000003.csv\n",
      "whoisdata65.00000000000003.csv\n",
      "whoisdata66.00000000000004.csv\n",
      "whoisdata67.00000000000004.csv\n",
      "whoisdata68.00000000000004.csv\n",
      "whoisdata69.00000000000004.csv\n",
      "whoisdata70.00000000000004.csv\n",
      "whoisdata71.00000000000004.csv\n",
      "whoisdata72.00000000000004.csv\n",
      "whoisdata73.00000000000004.csv\n",
      "whoisdata74.00000000000004.csv\n",
      "whoisdata75.00000000000004.csv\n",
      "whoisdata76.00000000000004.csv\n",
      "whoisdata77.00000000000004.csv\n",
      "whoisdata78.00000000000004.csv\n",
      "whoisdata79.00000000000004.csv\n",
      "whoisdata80.00000000000004.csv\n",
      "whoisdata81.00000000000006.csv\n",
      "whoisdata82.00000000000006.csv\n",
      "whoisdata83.00000000000006.csv\n",
      "whoisdata84.00000000000006.csv\n",
      "whoisdata85.00000000000006.csv\n",
      "whoisdata86.00000000000006.csv\n",
      "whoisdata87.00000000000006.csv\n",
      "whoisdata88.00000000000006.csv\n",
      "whoisdata89.00000000000006.csv\n",
      "whoisdata90.00000000000006.csv\n",
      "whoisdata91.00000000000006.csv\n",
      "whoisdata92.00000000000006.csv\n",
      "whoisdata93.00000000000006.csv\n",
      "whoisdata94.00000000000006.csv\n",
      "whoisdata95.00000000000006.csv\n",
      "whoisdata96.00000000000006.csv\n",
      "whoisdata97.00000000000006.csv\n",
      "whoisdata98.00000000000007.csv\n",
      "whoisdata0.0.csv\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (24,64,65,81,112,121,132,138,139,140) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/content/drive/Shareddrives/CSEC 620 Group 4/Final Project/csv')\n",
    "filelist = os.listdir('.')\n",
    "newframe = pd.DataFrame()\n",
    "for f in filelist:\n",
    "  if f.find('whoisdata') == 0:\n",
    "    print(f)\n",
    "    currentframe = pd.read_csv(f)\n",
    "    newframe = pd.concat([newframe, currentframe], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_v_EXRYy5kwB",
    "outputId": "6eedce67-f3b0-42ae-bd1b-a2957b741855",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671053994779,
     "user_tz": 300,
     "elapsed": 1046728,
     "user": {
      "displayName": "Dominic Adams",
      "userId": "18171972707617789133"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "350\n",
      "5198\n"
     ]
    }
   ],
   "source": [
    "benmal = []\n",
    "nummal = 0\n",
    "numbenign = 0\n",
    "for index, row in newframe.iterrows():\n",
    "  thisurl = row[\"originalurl\"]\n",
    "  mergedrow = dataset.loc[dataset[\"url\"] == thisurl]\n",
    "  benigncheck = mergedrow.iloc[0][\"label\"]\n",
    "  benmal.append(benigncheck)\n",
    "  if benigncheck == 0:\n",
    "    numbenign = numbenign + 1\n",
    "  else:\n",
    "    nummal = nummal + 1\n",
    "print(nummal)\n",
    "print(numbenign)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Splitting the data set"
   ],
   "metadata": {
    "id": "z9GkMk4Rsh8C"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "splitVal = int(len(newframe)*.2)\n",
    "testing_set1 = newframe.iloc[:splitVal,]\n",
    "testing_set2 = newframe.iloc[splitVal:(splitVal*2),]\n",
    "training_set = newframe.iloc[(splitVal*2):,]\n",
    "benmaltraining = benmal[(splitVal*2):]\n",
    "benmaltesting = benmal[:splitVal]\n",
    "benmaltesting2 = benmal[splitVal:(splitVal*2)]"
   ],
   "metadata": {
    "id": "EVTNVs34qiMy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "countries = {}\n",
    "for index, row in training_set.iterrows():\n",
    "  rowcountry = row[\"country\"]\n",
    "  if rowcountry in countries.keys():\n",
    "    countries[rowcountry] = countries[rowcountry] + 1\n",
    "  else:\n",
    "    countries[rowcountry] = 1\n",
    "\n",
    "for c in countries:\n",
    "  print(c, countries[c])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BR4f17jNYbSF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049142292,
     "user_tz": 300,
     "elapsed": 199,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "1efea931-0a61-4a08-e71c-be1403ea7377"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "US 1330\n",
      "nan 1346\n",
      "UK 5\n",
      "CA 94\n",
      "JP 18\n",
      "BR 57\n",
      "AU 10\n",
      "GB 64\n",
      "RU 12\n",
      "IN 29\n",
      "IS 81\n",
      "DE 21\n",
      "RO 15\n",
      "NZ 2\n",
      "Austria 4\n",
      "SE 4\n",
      "PA 13\n",
      "REDACTED FOR PRIVACY 11\n",
      "AT 4\n",
      "LU 3\n",
      "SI 1\n",
      "CN 51\n",
      "China 3\n",
      "NL 18\n",
      "CY 5\n",
      "CZ 4\n",
      "SN 2\n",
      "FR 17\n",
      "IT 7\n",
      "CR 2\n",
      "PE 2\n",
      "TH 3\n",
      "SK 1\n",
      "KR 3\n",
      "MX 1\n",
      "TR 3\n",
      "MY 2\n",
      "IE 1\n",
      "UA 2\n",
      "CH 6\n",
      "United Kingdom of Great Britain and Northern Ireland (the) 1\n",
      "my 1\n",
      "BE 3\n",
      "ES 11\n",
      "KN 1\n",
      "SG 3\n",
      "ID 6\n",
      "Malaysia 3\n",
      "PL 3\n",
      "BG 5\n",
      "PH 2\n",
      "FI 1\n",
      "SC 4\n",
      "NO 2\n",
      "cn 1\n",
      "PK 2\n",
      "BD 1\n",
      "EC 1\n",
      "CL 1\n",
      "VN 1\n",
      "EE 1\n",
      "HR 1\n",
      "KY 2\n",
      "DK 4\n",
      "BS 2\n",
      "MH 1\n",
      "HK 1\n",
      "HU 3\n",
      "IL 1\n",
      "GREECE 1\n",
      "ET 1\n",
      "KH 1\n",
      "ZA 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "regs = {}\n",
    "for index, row in training_set.iterrows():\n",
    "  rowreg = row[\"registrar\"]\n",
    "  if rowreg in regs.keys():\n",
    "    regs[rowreg] = regs[rowreg] + 1\n",
    "  else:\n",
    "    regs[rowreg] = 1\n",
    "\n",
    "for r in regs:\n",
    "  print(r, regs[r])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143582,
     "user_tz": 300,
     "elapsed": 1296,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "a791881c-acb8-4d2d-c190-42d6224dcf26",
    "id": "nqErv3frel3j"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloudflare, Inc. 17\n",
      "ALIBABA.COM SINGAPORE E-COMMERCE PRIVATE LIMITED 3\n",
      "Total Registrations 1\n",
      "nan 293\n",
      "MarkMonitor, Inc. 310\n",
      "Dynadot5 LLC 2\n",
      "GoDaddy.com, LLC 507\n",
      "DYNADOT, LLC 29\n",
      "123-Reg Limited 9\n",
      "Regional Network Information Center, JSC dba RU-CENTER 8\n",
      "Internet Domain Service BS Corp 12\n",
      "Network Solutions, LLC 224\n",
      "Aruba s.p.a. 11\n",
      "Alibaba Cloud Computing (Beijing) Co., Ltd. 11\n",
      "Namescout.com 6\n",
      "PSI-USA, Inc. dba Domain Robot 12\n",
      "MarkMonitor Inc. 168\n",
      "Go Daddy Domains Canada, Inc 3\n",
      "DIAMATRIX C.C. 1\n",
      "DNC Holdings, Inc 12\n",
      "GoDaddy Corporate Domains, LLC 26\n",
      "GMO INTERNET, INC. 14\n",
      "InterNetX GmbH 3\n",
      "GANDI SAS 13\n",
      "Amazon Registrar, Inc. 52\n",
      "IONOS SE 11\n",
      "Fasthosts Internet Ltd [Tag = LIVEDOMAINS] 6\n",
      "CSC CORPORATE DOMAINS, INC. 167\n",
      "RegistrarSafe, LLC 49\n",
      "Synergy Wholesale 2\n",
      "Google LLC 47\n",
      "TUCOWS, INC. 21\n",
      "TurnCommerce, Inc. DBA NameBright.com 20\n",
      "ENOM, INC. 81\n",
      "Key-Systems GmbH 46\n",
      "NAMECHEAP INC 99\n",
      "NIC.PE 1\n",
      "Digital Registra 5\n",
      "REGTIME-RU 1\n",
      "Freemium Kft. 1\n",
      "SNAPNAMES 35, LLC 1\n",
      "ICI - Registrar 2\n",
      "GIP RENATER 1\n",
      "Iconicnames LLC 1\n",
      "FastDomain Inc. 19\n",
      "Tool Domains Ltd 1\n",
      "Mihos.Net 1\n",
      "Kenyaweb.com Limited 1\n",
      "Marcaria.com LLC 1\n",
      "GoDaddy.com, LLC. [Tag = GODADDY] 4\n",
      "Wild West Domains, LLC 30\n",
      "Tucows.com Co. 5\n",
      "AKKY ONLINE SOLUTIONS, S.A. DE C.V. 3\n",
      "Media Elite Holdings Limited 3\n",
      "XIAMEN CHINASOURCE INTERNET SERVICE CO., LTD. 1\n",
      "easyDNS Technologies Inc. 6\n",
      "INWX GmbH 13\n",
      "MarkMonitor International Canada Ltd. 6\n",
      "Hong Kong Domain Name Registration Company Limited 3\n",
      "EPAG DOMAINSERVICES GmbH 1\n",
      "Domain.com, LLC 26\n",
      "REG-ZONER 4\n",
      "British Broadcasting Corporation [Tag = BBC] 1\n",
      "Namesilo, LLC 3\n",
      "GoDaddy.com 3\n",
      "REG-INTERNET-CZ 5\n",
      "Corporation Service Company 5\n",
      "Webnames.ca Inc. 9\n",
      "RegistryGate GmbH ( https://nic.at/registrar/228 ) 2\n",
      "Moniker Online Services LLC 21\n",
      "Eurodns S.A. 7\n",
      "CSL Computer Service Langenbach GmbH d/b/a joker.com 5\n",
      "Webtasy, d.o.o. 1\n",
      "Heart Internet Ltd t/a Heart Internet [Tag = HEARTINTERNET] 2\n",
      "Hong Kong Juming Network Technology Co., Ltd. 5\n",
      "MAFF Inc. 2\n",
      "REALTIME REGISTER B.V. 3\n",
      "Omnis Network, LLC 2\n",
      "Hostinger, UAB 5\n",
      "ТОВ “ІНТЕРНЕТ ІНВЕСТ” 3\n",
      "CSL Computer Service Langenbach GmbH d/b/a joker.com a German GmbH 1\n",
      "Consulting Service Sp. z o.o. 3\n",
      "Hosting Concepts B.V. d/b/a Openprovider 1\n",
      "17 Domain 1, Limited 2\n",
      "UDomainName.com LLC 1\n",
      "Global Domains Ltd [Tag = GDLTD] 1\n",
      "Ionos SE [Tag = 1AND1] 3\n",
      "Dynadot 1\n",
      "SURF B.V. 1\n",
      "江苏邦宁科技有限公司 1\n",
      "Tiger Technologies LLC 1\n",
      "DOMAIN NAME NETWORK PTY LTD 1\n",
      "Vodafone Limited t/a Vodafone.co.uk [Tag = VODAFONE] 1\n",
      "GRANSY S.R.O D/B/A SUBREG.CZ 3\n",
      "123-Reg Limited t/a 123-reg [Tag = 123-REG] 6\n",
      "Name.com, Inc. 22\n",
      "Launchpad, Inc. (HostGator) 7\n",
      "Hosting Concepts B.V. d/b/a Registrar.eu 6\n",
      "HITROST.COM domene in gostovanje 3\n",
      "PDR Ltd. d/b/a PublicDomainRegistry.com 36\n",
      "OVH, SAS 10\n",
      "Simply.com 1\n",
      "Register.com, Inc. 23\n",
      "NameSilo, LLC 14\n",
      "eName Technology Co.,Ltd. 7\n",
      "REGISTER S.P.A. 7\n",
      "Wix.Com Ltd. 2\n",
      "ENARTIA Single Member S.A. 1\n",
      "West263 International Limited 2\n",
      "DNSPod, Inc. 1\n",
      "Paragon Internet Group Ltd 1\n",
      "DOMAINPEOPLE, INC. 1\n",
      "Skyberate Internet Services 1\n",
      "Gname.com Pte. Ltd. 16\n",
      "Dynadot16 LLC 1\n",
      "CommuniGal Communication Ltd. 2\n",
      "DropCatch.com 883 LLC 1\n",
      "Loopia AB 6\n",
      "Easyspace Ltd. 2\n",
      "1-Grid 1\n",
      "CSC Corporate Domains (Canada) Company 3\n",
      "REGRU-RU 9\n",
      "DropCatch.com 1075 LLC 1\n",
      "dot-ca-registry.ca (Burmac Business Systems Ltd) 5\n",
      "DropCatch.com 674 LLC 1\n",
      "Domena.pl sp. z o.o. 4\n",
      "WEBNAMES.CA INC 13\n",
      "CanSpace Solutions Inc. 1\n",
      "nicar 2\n",
      "1API GmbH 5\n",
      "Instra Corporation Pty Ltd. 1\n",
      "INAMES CO., LTD. 2\n",
      "eNom, Inc. 6\n",
      "John Sisk [Tag = JSISK] 1\n",
      "DropCatch.com 985 LLC 2\n",
      "KPN 1\n",
      "007NAMES INC. 1\n",
      "A.R.C. Informatique Inc. 5\n",
      "RU-CENTER-RU 8\n",
      "Net Solution Hosting SRL 1\n",
      "Webcentral Group Limited dba Melbourne IT 6\n",
      "Gabia, Inc.(http://www.gabia.co.kr) 2\n",
      "Dreamscape Networks International Pte Ltd 5\n",
      "Tirupati Domains and Hosting Private Limited 1\n",
      "CSC Corporate Domains Inc. 1\n",
      "GKG.NET, INC. 2\n",
      "MediaCenter Hungary Kft. 1\n",
      "Register.ca Inc 1\n",
      "Gname 008 Inc 1\n",
      "Blacknight Internet Solutions Ltd. 1\n",
      "Sea Wasp, LLC 10\n",
      "Tucows Domains Inc. 76\n",
      "Onlinenic Inc 2\n",
      "Arsys Internet, S.L. dba NICLINE.COM 2\n",
      "COREhub, S.R.L. 1\n",
      "Sav.com, LLC - 26 1\n",
      "浙江贰贰网络有限公司 1\n",
      "Registrar.eu ( https://nic.at/registrar/648 ) 1\n",
      "WEBCC 5\n",
      "team.blue nl B.V. 5\n",
      "New Frontier, Inc. 3\n",
      "Romarg SRL 1\n",
      "ZigZagNames.com LLC 2\n",
      "Regione Toscana 1\n",
      "NOM-IQ Ltd dba Com Laude 13\n",
      "TLD Registrar Solutions Ltd 2\n",
      "Nameshield SAS 2\n",
      "Alphanet sp. z o.o. 1\n",
      "Realtime Register 4\n",
      "Dinahosting s.l. 3\n",
      "DomainSpot LLC 6\n",
      "UK Web.Solutions Direct Ltd [Tag = UKWSD] 1\n",
      "UK2 Limited [Tag = UK2NET] 1\n",
      "Websupport, s.r.o. 1\n",
      "Porkbun LLC 2\n",
      "Internic.ca Inc. 2\n",
      "北京中科三方网络技术有限公司 1\n",
      "NetEarth One Inc. d/b/a NetEarth 2\n",
      "INLEED 1\n",
      "Nics Telekomunikasyon A.S. 3\n",
      "Netsons S.r.l. 4\n",
      "CSC Corporate Domains, Inc. 6\n",
      "OwnRegistrar, Inc. 1\n",
      "BARBERO & Associates Ltd 1\n",
      "Gandi [Tag = GANDI] 2\n",
      "Namecamp Limited t/a Yay.com [Tag = YAYYAY] 1\n",
      "Net 4 India Limited 2\n",
      "Ascio Technologies Inc. Denmark &ndash; filial af Ascio Technologies Inc. USA [Tag = ASCIO] 1\n",
      "DreamHost LLC 3\n",
      "Markmonitor Inc. [Tag = MARKMONITOR] 2\n",
      "Fair Trade Domains, LLC 1\n",
      "ABOVE.COM PTY LTD. 1\n",
      "Xin Net Technology Corporation 8\n",
      "URL SOLUTIONS INC. 3\n",
      "NameSecure L.L.C. 2\n",
      "Dynadot8 LLC 1\n",
      "No registrar listed.  This domain is directly registered with Nominet. 9\n",
      "IHS Telekom, Inc 1\n",
      "xneelo (Pty) Ltd 2\n",
      "Plusnet Plc t/a Madasafish Broadband [Tag = MADASAFISH] 1\n",
      "ТОВ \"Геонiк Нет\" 3\n",
      "NIC Chile 8\n",
      "Hetzner Online GmbH 2\n",
      "Hosting Concepts B.V. 1\n",
      "In2net Network Inc. 2\n",
      "GoDaddy Online Services Cayman Islands Ltd. 3\n",
      "Consortium GARR 1\n",
      "MidWestDomains, LLC 1\n",
      "CloudFlare, Inc. 1\n",
      "Rebel.ca Corp. 3\n",
      "Inbrand AB 1\n",
      "One.com A/S 1\n",
      "LIQUIDNET Ltd. 2\n",
      "Gabia, Inc. 1\n",
      "DropCatch.com 595 LLC 2\n",
      "SAV.COM, LLC 4\n",
      "Hospedando.Com.Mx 1\n",
      "TLD Registrar Solutions Ltd. 2\n",
      "R01-RU 1\n",
      "Rebel.ca 2\n",
      "nazwa.pl sp. z o.o. 4\n",
      "Gandi SAS 6\n",
      "Authentic Web Inc. 2\n",
      "Internet Service Europe BV 2\n",
      "Atak Domain 2\n",
      "Ascio Technologies, Inc 5\n",
      "Endurance Digital Domain Technology LLP 1\n",
      "https://www.101domain.com/ 3\n",
      "http.net Internet GmbH 1\n",
      "Terranet (India) Private Limited 2\n",
      "Cronon GmbH 2\n",
      "Global Domain Name Trading Center Ltd 1\n",
      "Pair Domains 4\n",
      "Metaregistrar B.V. 2\n",
      "Go France Domains, LLC 2\n",
      "ТОВ \"Центр Інтернет-Імен України\" 2\n",
      "阿里云计算有限公司（万网） 3\n",
      "Instra Corporation Pty Ltd 2\n",
      "DropCatch.com 1162 LLC 1\n",
      "TLDS L.L.C. d/b/a SRSPlus 3\n",
      "SPRINTNAMES-RU 1\n",
      "Dynadot13 LLC 1\n",
      "Coherent Limited [Tag = COHERENT-NZ] 1\n",
      "Gandi 2\n",
      "ТОВ \"НІК.ЮЕЙ\" 1\n",
      "Dynadot, LLC 1\n",
      "Namespro Solutions Inc. 1\n",
      "BigRock Solutions Ltd. 1\n",
      "CSL GmbH Computer Service Langenbach   d/b/a  joker.com 1\n",
      "CV. Jogjacamp 1\n",
      "DropCatch.com 365 LLC 1\n",
      "Beget LLC 1\n",
      "DREAMHOST 7\n",
      "1&1 IONOS SE 1\n",
      "home.pl S.A. 3\n",
      "Converged Communication Solutions Limited [Tag = CONVERGED] 1\n",
      "EuroDNS SA 1\n",
      "Domaingazelle.com LLC 1\n",
      "10DENCEHISPAHARD, S.L 3\n",
      "TECNOCRATICA CENTRO DE DATOS, S.L. 3\n",
      "Bizcn.com,Inc. 1\n",
      "Misk.com, Inc. 1\n",
      "Cronon AG 1\n",
      "GMO Internet, Inc. d/b/a Onamae.com 1\n",
      "Xiamen 35.Com Technology Co., Ltd 1\n",
      "KIFCORP 1\n",
      "DonDominio (SCIP) 1\n",
      "DropCatch.com 1442 LLC 1\n",
      "Ledl.net GmbH ( https://nic.at/registrar/32 ) 1\n",
      "ORANGE 1\n",
      "easyDNS Technologies, Inc. 4\n",
      "Registrar.eu 4\n",
      "DropCatch.com 1098 LLC 1\n",
      "EURODNS S.A. 1\n",
      "Stichting Registrar of Last Resort Foundation 1\n",
      "NameCheap, Inc. 16\n",
      "eNom LLC [Tag = ENOM] 2\n",
      "Squarespace Domains LLC 1\n",
      "BEIJING SANFRONT INFORMATION TECHNOLOGY CO., LTD 1\n",
      "DropCatch.com 1294 LLC 1\n",
      "DropCatch.com 631 LLC 1\n",
      "CNA Servizi s.c.r.l. 1\n",
      "US Locality 2\n",
      "Register S.p.a. 2\n",
      "DropCatch.com 1483 LLC 1\n",
      "NS3 S.r.l. 1\n",
      "Aerotek Bilisim Sanayi ve Ticaret AS 1\n",
      "Click Registrar, Inc. d/b/a publicdomainregistry.com 2\n",
      "WebReus 2\n",
      "Réseau Internet Québec Inc. 3\n",
      "SNAPNAMES 44, LLC 1\n",
      "Infomaniak Network SA 1\n",
      "REG-GRANSY 1\n",
      "Internet Invest, Ltd. dba Imena.ua 1\n",
      "Claus Web SRL 3\n",
      "Domain International Services Limited 1\n",
      "NetArt Registrar Sp. z o.o. 1\n",
      "Ehinet S.r.l. 1\n",
      "DropCatch.com 1304 LLC 1\n",
      "Avant.si d.o.o. 1\n",
      "Genesys Informatica S.r.l. 1\n",
      "Domeneshop AS dba domainnameshop.com 1\n",
      "(Funio) - Miss Group Canada Inc 1\n",
      "Lexsynergy Limited 3\n",
      "DomainName Path, Inc. 1\n",
      "NET-CHINESE 1\n",
      "The Registry at Info Avenue, LLC d/b/a Spirit Communications 1\n",
      "Adriahost 1\n",
      "CBN Registrar 1\n",
      "Axxess DSL 1\n",
      "MSERWIS Sp.z o.o. sp. k. 1\n",
      "Promo People, Inc. [Tag = PROMOPEOPLE] 1\n",
      "Libyan Spider Network (int) 2\n",
      "Zala Creative LTD 1\n",
      "Epik Holdings Inc 2\n",
      "P.A. Viet Nam Company Limited 1\n",
      "北京新网数码信息技术有限公司 1\n",
      "The Registrar Company B.V. 2\n",
      "Domaincapitan.com LLC 1\n",
      "上海贝锐信息科技股份有限公司 3\n",
      "DropCatch.com 623 LLC 1\n",
      "BEGET-RU 1\n",
      "JIANGSU BANGNING SCIENCE & TECHNOLOGY CO. LTD 3\n",
      "Dynadot, LLC t/a Dynadot [Tag = DYNADOT] 1\n",
      "Deluxe Small Business Sales, Inc. d/b/a Aplus.net 3\n",
      "pair Networks, Inc. d/b/a pair Domains 1\n",
      "DropCatch.com 1013 LLC 1\n",
      "Digital Media Technology Sp. z o.o. 2\n",
      "NETIM 2\n",
      "Cyntra Ventures Ltd [Tag = CYNTRA] 1\n",
      "eNom, LLC 1\n",
      "OVH SAS 1\n",
      "INTERNET CZ, a.s. 2\n",
      "cyber_Folks S.A. 3\n",
      "ODTU Gelistirme Vakfi Bilgi Teknolojileri Sanayi Ve Ticaret Anonim Sirketi 1\n",
      "mat bao corporation 1\n",
      "Tool Domains EOOD t/a Salestrar.com [Tag = SALESTRAR] 1\n",
      "CSC Corporate Domains 1\n",
      "AZ.pl Sp. z o.o. 2\n",
      "SALENAMES-RU 1\n",
      "Host4Africa 1\n",
      "MESH DIGITAL LIMITED 3\n",
      "Globtel Internet Szymon Hersztek 1\n",
      "Epik Inc. 2\n",
      "DropCatch.com 606 LLC 1\n",
      "DropCatch.com 391 LLC 1\n",
      "LinQhost 1\n",
      "ANNULET, INC 1\n",
      "DropCatch.com 1191 LLC 1\n",
      "Cloud Center Finland Oy 1\n",
      "Sav.com LLC 1\n",
      "Webglobe, a.s. 1\n",
      "Whois Corp. 1\n",
      "Afrihost 1\n",
      "AutoDNS 1\n",
      "Catalyst2 Services Ltd t/a catalyst2 [Tag = CATALYST2] 1\n",
      "LiveDNS Ltd 1\n",
      "CommuniGal Communications Ltd. 1\n",
      "Dropcatch Landing Spot LLC 1\n",
      "ITnet s.r.l. 2\n",
      "Protocol Internet Technology Limited t/a Hosting Ireland 1\n",
      "Native Logic Ltd. t/a nativespace [Tag = NATIVESPACE] 1\n",
      "Gname 007 Inc 1\n",
      "Gal Communication (CommuniGal) Ltd. 1\n",
      "REG-MOJEID 1\n",
      "NICENIC INTERNATIONAL GROUP CO., LIMITED 1\n",
      "SCALEWAY 2\n",
      "Mesh Digital Limited 1\n",
      "NET TUNER CORP. DBA WEBMASTERS.COM 1\n",
      "Hostnet B.V. 1\n",
      "Awesome Projects SRL 1\n",
      "NameSilo Technologies Corp. 1\n",
      "Metaregistrar BV 1\n",
      "OVH 1\n",
      "DOMAINSHOP-RU 1\n",
      "Sav.com, LLC 1\n",
      "Isimtescil Bilisim A.S. 1\n",
      "Gname 020 Inc 1\n",
      "22NET, INC. 1\n",
      "LCN.com Ltd [Tag = LCN] 1\n",
      "Epik, Inc. 1\n",
      "acens Technologies, S.L.U. 1\n",
      "Easily Limited t/a easily.co.uk [Tag = WEBCONSULTANCY] 1\n",
      "ADISTA 1\n",
      "Blue Angel Domains LLC 1\n",
      "SAV.COM, LLC - 13 1\n",
      "DropCatch.com 1173 LLC 1\n",
      "Zhengzhou Century Connect Electronic Technology Development Co., Ltd 1\n",
      "Promo People Inc. 1\n",
      "ACTIVE-RU 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dns = {}\n",
    "for index, row in training_set.iterrows():\n",
    "  rowdns = row[\"dnssec\"]\n",
    "  if rowdns in dns.keys():\n",
    "    dns[rowdns] = dns[rowdns] + 1\n",
    "  elif 'unsigned' in str(rowdns).lower() and (rowdns != 'unsigned'):\n",
    "    dns[\"unsigned\"] = dns[\"unsigned\"] + 1\n",
    "  else:\n",
    "    dns[rowdns] = 1\n",
    "\n",
    "for r in dns:\n",
    "  print(r, dns[r])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSGb60Upht_p",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143583,
     "user_tz": 300,
     "elapsed": 39,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "ff95a4b9-c5d0-48ba-a8ce-24e321f00ca2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "signedDelegation 72\n",
      "unsigned 2672\n",
      "nan 527\n",
      "Inactive 12\n",
      "no 19\n",
      "Signed delegation 7\n",
      "yes 13\n",
      "signed delegation 7\n",
      "['signedDelegation', 'signed'] 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from numpy.lib.function_base import percentile\n",
    "percentages = {}\n",
    "percentagerow = []\n",
    "\n",
    "for index, row in training_set.iterrows():\n",
    "  rowdomain = row[\"domain_name\"]\n",
    "  num = 0\n",
    "  lett = 0\n",
    "  for char in rowdomain:\n",
    "    if char.isalpha():\n",
    "      lett += 1\n",
    "    elif char.isnumeric():\n",
    "      num += 1\n",
    "  perc = round(num/(num+lett), 1)\n",
    "  percentagerow.append(perc)\n",
    "  if perc in percentages.keys():\n",
    "    percentages[perc] = percentages[perc] + 1\n",
    "  else:\n",
    "    percentages[perc] =  1\n",
    "\n",
    "for p in percentages:\n",
    "  print(p, percentages[p])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePDXCE3SkmQP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143583,
     "user_tz": 300,
     "elapsed": 35,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "3a4c557a-7267-417b-cbf9-d04313b787e1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0 3194\n",
      "0.1 57\n",
      "0.2 48\n",
      "0.3 18\n",
      "0.4 6\n",
      "0.5 4\n",
      "0.7 2\n",
      "0.6 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "url1 = le1.fit_transform(training_set[\"originalurl\"])\n",
    "countries = le1.fit_transform(training_set[\"country\"])\n",
    "features1 = [[url1[i], countries[i]] for i in range(0, len(url1))]\n",
    "label1 = le1.fit_transform(benmaltraining)\n",
    "\n",
    "model1 = GaussianNB()\n",
    "model1.fit(features1, label1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LOfC2Y_2tutz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143583,
     "user_tz": 300,
     "elapsed": 33,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "e3f600c3-920a-4b84-b2fa-ec88de48160f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "le2 = preprocessing.LabelEncoder()\n",
    "url2 = le2.fit_transform(training_set[\"originalurl\"])\n",
    "regs = le2.fit_transform(training_set[\"registrar\"])\n",
    "features2 = [[url2[i], regs[i]] for i in range(0, len(url2))]\n",
    "label2 = le2.fit_transform(benmaltraining)\n",
    "model2 = GaussianNB()\n",
    "model2.fit(features2, label2)"
   ],
   "metadata": {
    "id": "7_t61UINxZa9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143584,
     "user_tz": 300,
     "elapsed": 32,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "46f29b2d-193b-4a08-d6d6-5218191d67c0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "le3 = preprocessing.LabelEncoder()\n",
    "url3 = le3.fit_transform(training_set[\"originalurl\"])\n",
    "dnses = le3.fit_transform(training_set[\"dnssec\"])\n",
    "features3 = [[url3[i], dnses[i]] for i in range(0, len(url3))]\n",
    "label3 = le3.fit_transform(benmaltraining)\n",
    "model3 = GaussianNB()\n",
    "model3.fit(features3, label3)"
   ],
   "metadata": {
    "id": "ZV-HvnI5xpBx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143584,
     "user_tz": 300,
     "elapsed": 29,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "931e9012-a164-4e70-b06f-7ccc4154d18f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "le4 = preprocessing.LabelEncoder()\n",
    "url4 = le4.fit_transform(training_set[\"originalurl\"])\n",
    "percents = le4.fit_transform(percentagerow)\n",
    "features4 = [[url4[i], percents[i]] for i in range(0, len(url4))]\n",
    "label4 = le4.fit_transform(benmaltraining)\n",
    "model4 = GaussianNB()\n",
    "model4.fit(features4, label4)"
   ],
   "metadata": {
    "id": "I8t04xM0x66I",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143585,
     "user_tz": 300,
     "elapsed": 28,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "09fc9a02-42e8-4e21-cd7d-7f92ec0dfaee"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test1url = le1.fit_transform(testing_set1[\"originalurl\"])\n",
    "test1country = le1.fit_transform(testing_set1[\"country\"])\n",
    "test1feats = [[test1url[i], test1country[i]] for i in range(0, len(test1url))]\n",
    "test1final = model1.predict(test1feats)\n",
    "test1final"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXyh2BoIrtef",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143585,
     "user_tz": 300,
     "elapsed": 26,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "c8ba3a9f-fc33-4c13-f672-a200acc87dce"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test2url = le2.fit_transform(testing_set1[\"originalurl\"])\n",
    "test2reg = le2.fit_transform(testing_set1[\"registrar\"])\n",
    "test2feats = [[test2url[i], test2reg[i]] for i in range(0, len(test2url))]\n",
    "test2final = model2.predict(test2feats)\n",
    "test2final"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143586,
     "user_tz": 300,
     "elapsed": 25,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "99b74f53-78e3-4ef4-8a0b-889694868ba0",
    "id": "2fthpNEHusIY"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test3url = le3.fit_transform(testing_set1[\"originalurl\"])\n",
    "test3dns = le3.fit_transform(testing_set1[\"dnssec\"])\n",
    "test3feats = [[test3url[i], test3dns[i]] for i in range(0, len(test3url))]\n",
    "test3final = model3.predict(test3feats)\n",
    "test3final"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143587,
     "user_tz": 300,
     "elapsed": 24,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "cf0e0d9c-95ae-4f1a-ce28-609e942caeec",
    "id": "6Zxr9GmfvgI1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "percenttest = []\n",
    "\n",
    "for index, row in testing_set1.iterrows():\n",
    "  rowdomain = row[\"domain_name\"]\n",
    "  num = 0\n",
    "  lett = 0\n",
    "  for char in rowdomain:\n",
    "    if char.isalpha():\n",
    "      lett += 1\n",
    "    elif char.isnumeric():\n",
    "      num += 1\n",
    "  perc = round(num/(num+lett), 1)\n",
    "  percenttest.append(perc)\n",
    "\n",
    "test4url = le4.fit_transform(testing_set1[\"originalurl\"])\n",
    "test4percent = le4.fit_transform(percenttest)\n",
    "test4feats = [[test4url[i], test4percent[i]] for i in range(0, len(test4url))]\n",
    "test4final = model4.predict(test4feats)\n",
    "test4final"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143588,
     "user_tz": 300,
     "elapsed": 24,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "58a828ad-61c0-4cf3-ef3e-d1b7e5aac941",
    "id": "qLBLYy1vv5Fv"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# this is a function to actually test naive bayes and get results back for any given testing set. used with the svm\n",
    "def nb(testingset):\n",
    "  test1url = le1.fit_transform(testingset[\"originalurl\"])\n",
    "  test1country = le1.fit_transform(testingset[\"country\"])\n",
    "  test1feats = [[test1url[i], test1country[i]] for i in range(0, len(test1url))]\n",
    "  test1finalf = model1.predict(test1feats)\n",
    "  \n",
    "  test2url = le2.fit_transform(testingset[\"originalurl\"])\n",
    "  test2reg = le2.fit_transform(testingset[\"registrar\"])\n",
    "  test2feats = [[test2url[i], test2reg[i]] for i in range(0, len(test2url))]\n",
    "  test2finalf = model2.predict(test2feats)\n",
    "\n",
    "  test3url = le3.fit_transform(testingset[\"originalurl\"])\n",
    "  test3dns = le3.fit_transform(testingset[\"dnssec\"])\n",
    "  test3feats = [[test3url[i], test3dns[i]] for i in range(0, len(test3url))]\n",
    "  test3finalf = model3.predict(test3feats)\n",
    "\n",
    "  percenttest = []\n",
    "\n",
    "  for index, row in testingset.iterrows():\n",
    "    rowdomain = row[\"domain_name\"]\n",
    "    num = 0\n",
    "    lett = 0\n",
    "    for char in rowdomain:\n",
    "      if char.isalpha():\n",
    "        lett += 1\n",
    "      elif char.isnumeric():\n",
    "        num += 1\n",
    "    perc = round(num/(num+lett), 1)\n",
    "    percenttest.append(perc)\n",
    "\n",
    "  test4url = le4.fit_transform(testingset[\"originalurl\"])\n",
    "  test4percent = le4.fit_transform(percenttest)\n",
    "  test4feats = [[test4url[i], test4percent[i]] for i in range(0, len(test4url))]\n",
    "  test4finalf = model4.predict(test4feats)\n",
    "\n",
    "  return [test1finalf, test2finalf, test3finalf, test4finalf]"
   ],
   "metadata": {
    "id": "mP_uenE-tMHC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM Aggregation"
   ],
   "metadata": {
    "id": "IGHxl2z9ja3r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# this is the actual svm function. the trainingdata being passed in is a 2d matrix where each row is one entry and testing data is the same\n",
    "# maybe try changing the kernel since the data is so bad atm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def svm_aggregate(trainingdata, testingdata):\n",
    "  y_train = benmaltesting\n",
    "  y_test = benmaltesting2\n",
    "  x_train = trainingdata\n",
    "  x_test = testingdata\n",
    "  svmclassifier = SVC(kernel='rbf')\n",
    "  svmclassifier.fit(x_train, y_train)\n",
    "  y_predictions = svmclassifier.predict(x_test)\n",
    "  print(classification_report(y_test,y_predictions))"
   ],
   "metadata": {
    "id": "spZ8-wJIjadt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# this is a helper function just to make transforming the data easier. it takes the array of each of the test results and makes the entries row-by-row instead of in each column if im not mistaken in how it is\n",
    "def aggregator(data):\n",
    "  outputdata = []\n",
    "  i = 0\n",
    "  row = []\n",
    "  while i < len(data[0]):\n",
    "    for d in data:\n",
    "      row.append(d[i])\n",
    "    outputdata.append(row)\n",
    "    row = []\n",
    "    i+=1\n",
    "  return outputdata"
   ],
   "metadata": {
    "id": "cFxuj9vrs0Df"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# this is the handler function for svm, it manipulates the data into a useable form for the svm then calls the svm_aggregate function\n",
    "# d2aggregate is the training data that needs to be aggregated. this comes from naive bayes' first testing set\n",
    "def svm_handler(d2aggregate):\n",
    "  trainingdata = aggregator(d2aggregate)\n",
    "  testingdata = aggregator(nb(testing_set2))\n",
    "  svm_aggregate(trainingdata, testingdata)\n",
    "\n",
    "svm_handler([test1final, test2final, test3final, test4final])"
   ],
   "metadata": {
    "id": "XG0sWLnDkbiC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671049143590,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "Gregory Henigman",
      "userId": "11146979931616988706"
     }
    },
    "outputId": "ccdda765-40f5-4cf3-e496-70c34b8ff3cf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1040\n",
      "           1       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.94      1109\n",
      "   macro avg       0.47      0.50      0.48      1109\n",
      "weighted avg       0.88      0.94      0.91      1109\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
